{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85d17d5",
   "metadata": {},
   "source": [
    "# Scaling TF-IDF by GLoVe Vectors. \n",
    "\n",
    "With running and preforming analysis on the Psalms with BERT and SBERT. We can build comparable results with `GLoVe` and `TF-IDF`. Both BERT and SBERT, are created to learn and understand the meaning of a document. Combining `GLoVe` and `TF-IDF`, makes this happen well becasuse of the following: \n",
    "- `GLoVe` -Gathers and provides the semantic meaning of a document\n",
    "- `TF-IDF`- Gathers and provides the importance of the words within a document. <br>\n",
    "\n",
    "Together both of these help to create words embedings, simillar to **BERT** and **SBERT**. \n",
    "\n",
    "## Loading the models.\n",
    "\n",
    "To begin, we need to get access to the respected matrices. \n",
    "\n",
    "### TF-IDF Mtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fd12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/caden/st_david-s-beacon/website/data/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../data/models/\")\n",
    "\n",
    "# confirming directory location\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3fb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# getting the pickle file ready to be used\n",
    "with open(\"psalms_tfidf_matrix.pickle\", \"rb\") as file:\n",
    "    tfidf_matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05a67cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abasement</th>\n",
       "      <th>abated</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abhorred</th>\n",
       "      <th>abhors</th>\n",
       "      <th>abide</th>\n",
       "      <th>abides</th>\n",
       "      <th>abideth</th>\n",
       "      <th>...</th>\n",
       "      <th>zacharias</th>\n",
       "      <th>zalmon</th>\n",
       "      <th>zalmunna</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zebah</th>\n",
       "      <th>zebulun</th>\n",
       "      <th>zeeb</th>\n",
       "      <th>zion</th>\n",
       "      <th>ziphites</th>\n",
       "      <th>zoan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Bible, 1)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 2)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 3)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 4)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 5)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 146)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 147)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 148)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 149)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 150)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 3416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                aaron  abandon  abasement  abated  abhor  abhorred    abhors  \\\n",
       "(Bible, 1)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 2)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 3)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 4)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 5)        0.0      0.0        0.0     0.0    0.0       0.0  0.158926   \n",
       "...               ...      ...        ...     ...    ...       ...       ...   \n",
       "(Psalter, 146)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 147)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 148)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 149)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 150)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "\n",
       "                abide  abides  abideth  ...  zacharias  zalmon  zalmunna  \\\n",
       "(Bible, 1)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 2)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 3)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 4)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 5)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "...               ...     ...      ...  ...        ...     ...       ...   \n",
       "(Psalter, 146)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 147)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 148)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 149)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 150)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "\n",
       "                zeal  zebah  zebulun  zeeb      zion  ziphites  zoan  \n",
       "(Bible, 1)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 2)       0.0    0.0      0.0   0.0  0.073937       0.0   0.0  \n",
       "(Bible, 3)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 4)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 5)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "...              ...    ...      ...   ...       ...       ...   ...  \n",
       "(Psalter, 146)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Psalter, 147)   0.0    0.0      0.0   0.0  0.072535       0.0   0.0  \n",
       "(Psalter, 148)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Psalter, 149)   0.0    0.0      0.0   0.0  0.077526       0.0   0.0  \n",
       "(Psalter, 150)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "\n",
       "[301 rows x 3416 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f46cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/caden/st_david-s-beacon/website/scripts/fall 2025\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../../scripts/fall 2025\")\n",
    "\n",
    "# confirming directory location\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2568bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = {}\n",
    "\n",
    "with open(\"word_embeddings/vectors.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()        # split by spaces\n",
    "        word = parts[0]                     # first part is the word\n",
    "        vector = [float(x) for x in parts[1:]]  # rest are floats\n",
    "        glove_vectors[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7f87ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.021994, -0.631385, 0.569249, 0.334187, 0.554362, -0.410044, 0.164385, -0.119174, -0.35521, -0.456071, -0.087812, 0.339608, -0.019018, 0.514807, -0.094819, 0.41575, -0.166678, -0.574218, -0.477443, 0.250952, -0.012132, 0.18146, -0.301734, -0.647822, -0.450255, -0.3021, -0.17963, -0.939884, -0.343672, 0.585902, 0.888336, -0.932369, -0.305825, 0.403676, 0.730054, -0.816096, 0.869968, -0.348525, 0.286317, 0.133632, 0.134216, 0.300281, -0.600992, 0.212036, -0.273939, 0.116611, -0.131435, -0.734738, 0.365701, 0.118773, -0.285641, 0.146441, 0.254088, -0.414569, 0.056565, 0.34931, -0.614233, -0.574028, 0.959849, 0.0028, 0.069579, 0.222327, -0.6138, -0.152186, 0.38382, -0.114777, 0.837871, -0.151692, -0.651244, 0.089738, 0.586226, 0.263406, -0.497665, -0.867083, 0.023695, -0.554509, 0.475563, -0.242137, -0.130188, 0.123817, -0.207041, 0.238688, -0.043009, -0.650134, -0.117041, -0.303468, 0.0882, 1.002656, 0.196697, -0.103976, -0.231937, 0.025503, -0.136759, -0.364505, -0.196236, -0.578493, -0.663938, 0.131388, 0.606624, 0.227304]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "print(glove_vectors[\"aaron\"])  # prints vector for \"the\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6428d8",
   "metadata": {},
   "source": [
    "\n",
    "### Word-Level Embedding\n",
    "\n",
    "For a single word `w` in a document `d`:\n",
    "\n",
    "$$\n",
    "\\mathbf{e}_w = \\text{tfidf}(w, d) \\cdot \\mathbf{v}_w\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "* `v_w` = GloVe embedding of word `w` (dimension `d`)\n",
    "* `tfidf(w, d)` = TF-IDF weight of word `w` in document `d`\n",
    "* `e_w` = the TF-IDF–weighted embedding of that word\n",
    "\n",
    "\n",
    "\n",
    "### Document-Level Embedding\n",
    "\n",
    "\n",
    "For a document `d` with words `w_1, w_2, ..., w_n`:\n",
    "\n",
    "### Un-normalized weighted sum\n",
    "\n",
    "$$\n",
    "\\mathbf{E}*d = \\sum*{i=1}^{n} \\text{tfidf}(w_i, d) \\cdot \\mathbf{v}_{w_i}\n",
    "$$\n",
    "\n",
    "* This is the **sum of all TF-IDF–weighted word embeddings** in the document\n",
    "* Longer documents naturally have larger magnitudes\n",
    "\n",
    "### Optional normalization\n",
    "\n",
    "To avoid bias toward long documents:\n",
    "\n",
    "$$\n",
    "\\mathbf{E}*d = \\frac{\\sum*{i=1}^{n} \\text{tfidf}(w_i, d) \\cdot \\mathbf{v}*{w_i}}{\\sum*{i=1} \\text{tfidf}(w_i, d)}\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "* Now `E_d` is the **average TF-IDF–weighted embedding** for the document\n",
    "* This is the typical **document-level embedding** used for search, clustering, or similarity comparisons\n",
    "\n",
    "lets work on the single word embedding, working with the word **aaron**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1183e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.021994 -0.631385  0.569249  0.334187  0.554362 -0.410044  0.164385\n",
      " -0.119174 -0.35521  -0.456071 -0.087812  0.339608 -0.019018  0.514807\n",
      " -0.094819  0.41575  -0.166678 -0.574218 -0.477443  0.250952 -0.012132\n",
      "  0.18146  -0.301734 -0.647822 -0.450255 -0.3021   -0.17963  -0.939884\n",
      " -0.343672  0.585902  0.888336 -0.932369 -0.305825  0.403676  0.730054\n",
      " -0.816096  0.869968 -0.348525  0.286317  0.133632  0.134216  0.300281\n",
      " -0.600992  0.212036 -0.273939  0.116611 -0.131435 -0.734738  0.365701\n",
      "  0.118773 -0.285641  0.146441  0.254088 -0.414569  0.056565  0.34931\n",
      " -0.614233 -0.574028  0.959849  0.0028    0.069579  0.222327 -0.6138\n",
      " -0.152186  0.38382  -0.114777  0.837871 -0.151692 -0.651244  0.089738\n",
      "  0.586226  0.263406 -0.497665 -0.867083  0.023695 -0.554509  0.475563\n",
      " -0.242137 -0.130188  0.123817 -0.207041  0.238688 -0.043009 -0.650134\n",
      " -0.117041 -0.303468  0.0882    1.002656  0.196697 -0.103976 -0.231937\n",
      "  0.025503 -0.136759 -0.364505 -0.196236 -0.578493 -0.663938  0.131388\n",
      "  0.606624  0.227304]\n",
      "0.0\n",
      "[ 0. -0.  0.  0.  0. -0.  0. -0. -0. -0. -0.  0. -0.  0. -0.  0. -0. -0.\n",
      " -0.  0. -0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0. -0. -0.  0.  0. -0.\n",
      "  0. -0.  0.  0.  0.  0. -0.  0. -0.  0. -0. -0.  0.  0. -0.  0.  0. -0.\n",
      "  0.  0. -0. -0.  0.  0.  0.  0. -0. -0.  0. -0.  0. -0. -0.  0.  0.  0.\n",
      " -0. -0.  0. -0.  0. -0. -0.  0. -0.  0. -0. -0. -0. -0.  0.  0.  0. -0.\n",
      " -0.  0. -0. -0. -0. -0. -0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_aaron = np.array(glove_vectors[\"aaron\"])\n",
    "\n",
    "print(glove_aaron)\n",
    "\n",
    "tfidf_aaron = tfidf_matrix.iloc[0][\"aaron\"]\n",
    "print(tfidf_aaron)\n",
    "\n",
    "\n",
    "# prototype of scaling \n",
    "scaled = glove_aaron * tfidf_aaron\n",
    "\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe4126",
   "metadata": {},
   "source": [
    "With this, we have the basis for the entrie scaling that is trying to be achieved. Let's build the function to handle the numerator of the document embe3dding equation. \n",
    "\n",
    "Before we get to that, we need to convert all of the GLoVe vectors to arrays, so they can be maniplated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e25fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in glove_vectors:\n",
    "    glove_vectors[word] = np.array(glove_vectors[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc4440aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0.,  0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,\n",
       "        0., -0.,  0., -0., -0., -0.,  0., -0.,  0., -0., -0., -0., -0.,\n",
       "       -0., -0., -0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0., -0.,  0.,\n",
       "        0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,  0.,\n",
       "        0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0.,\n",
       "       -0.,  0., -0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0., -0.,\n",
       "       -0.,  0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0., -0., -0.,\n",
       "        0., -0., -0., -0., -0., -0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_embed(doc_index, word):\n",
    "    glove_vector = np.array(glove_vectors[word])\n",
    "    tfidf_value = tfidf_matrix.iloc[doc_index][word]\n",
    "    return glove_vector * tfidf_value\n",
    "\n",
    "# Testing for the word \"aaron\"\n",
    "word_embed(0, \"aaron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5438b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Adding logic to skip words that are missing\n",
    "def word_embed(doc_index, word):\n",
    "    if word in glove_vectors:\n",
    "        glove_vector = np.array(glove_vectors[word])\n",
    "        tfidf_value = tfidf_matrix.iloc[doc_index][word]\n",
    "        return glove_vector * tfidf_value\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "# Testing for the word \"aaron\"\n",
    "print(word_embed(0, \"the\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5379c0",
   "metadata": {},
   "source": [
    "With this working we can use it to build the numerator of the equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad3075cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of words or column if the TF-IDF Matrix to go through\n",
    "num_words = tfidf_matrix.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cfa5cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words checked: 3416\n",
      "Words missing in GloVe: 2\n",
      "Percentage missing: 0.06%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "doc_index = 0\n",
    "count = 0\n",
    "missed = 0\n",
    "\n",
    "for i in range(num_words):\n",
    "    word = tfidf_matrix.columns[i]\n",
    "    value = word_embed(doc_index, word)\n",
    "    if value is None:\n",
    "        missed += 1\n",
    "    count += 1\n",
    "\n",
    "print(f\"Total words checked: {count}\")\n",
    "print(f\"Words missing in GloVe: {missed}\")\n",
    "print(f\"Percentage missing: {missed / count * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cfc56",
   "metadata": {},
   "source": [
    "We can see, we are only missing two words in total. At this point, in the testing phase, we can move on an try to fix this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa62c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "Summation Total: [ 0.99844336  1.07775893 -0.8927152  -1.20848783 -0.58902123 -0.61221441\n",
      " -1.47549233 -0.38461311  1.11098091  0.41525863  1.38311392  0.31797648\n",
      "  0.11635139 -0.07975584 -0.5770555  -0.61215479 -0.43169565 -1.00712571\n",
      "  0.27586399  1.33520889  0.73448332 -0.80206696  1.83952995 -0.93761417\n",
      " -0.65491804  1.20168885 -0.46295066 -0.40645041 -0.17887081  1.02558415\n",
      "  0.10761852 -0.73401962 -0.98117217  0.38654099 -1.26535867  0.33392192\n",
      "  1.41440314  0.52873145 -0.86716699 -0.17688443  1.76593105  0.24458425\n",
      "  0.412535    0.66313905  0.08618248  0.01938377 -0.05764216 -0.55345339\n",
      " -1.22328637  0.24669065  0.40177217  0.33170781 -0.6347872   0.76387912\n",
      "  0.12991239 -0.5593725   0.65528791 -0.30999396 -0.58648846  1.33802322\n",
      "  0.06075495  0.22671971  0.50845854  0.78456215  0.51257826  0.27712267\n",
      " -1.21725281 -0.43697481 -0.0048035  -0.92071933 -0.00739128 -0.75696834\n",
      "  0.52522951 -0.23924555 -0.37763763 -0.60823845 -0.34046993 -0.19868455\n",
      " -1.02586513  0.48948615  0.82529666 -0.20919496 -0.28920789 -0.21221704\n",
      " -1.34177344 -0.59748917  0.37368711 -0.68248143 -0.07078512  0.13679254\n",
      "  0.68200461  0.09657408 -0.18196031  0.10166348 -1.90027701  1.03734648\n",
      "  1.45719077  0.4067907   1.12704498 -0.17711561]\n",
      "Total words checked: 3416\n",
      "Words missing in GloVe: 2\n",
      "Percentage missing: 0.06%\n"
     ]
    }
   ],
   "source": [
    "## Applying the Summation part of the numerator\n",
    "embedding_dim = len(next(iter(glove_vectors.values())))  # get embedding dimension\n",
    "doc_index = 0\n",
    "count = 0\n",
    "missed = 0\n",
    "total = np.zeros(embedding_dim)  # initialize as array\n",
    "\n",
    "for i in range(num_words):\n",
    "    word = tfidf_matrix.columns[i]\n",
    "    value = word_embed(doc_index, word)\n",
    "    if value is not None:\n",
    "        total += value\n",
    "    else:\n",
    "        missed += 1\n",
    "    count += 1\n",
    "\n",
    "print(f\"Summation Total: {total}\")\n",
    "print(f\"Total words checked: {count}\")\n",
    "print(f\"Words missing in GloVe: {missed}\")\n",
    "print(f\"Percentage missing: {missed / count * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550aac3c",
   "metadata": {},
   "source": [
    "With the numerator programed it sohlud be easy to implement the denominator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(embedding_dim):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bee7b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.621319936521571\n"
     ]
    }
   ],
   "source": [
    "## Applying the Summation part of the numerator\n",
    "doc_index = 0\n",
    "denominator = 0\n",
    "\n",
    "for i in range(num_words):\n",
    "    word = tfidf_matrix.columns[i]\n",
    "    # Making sure the word in in the glove vector\n",
    "    if word in glove_vectors:\n",
    "        denominator += tfidf_matrix.iloc[doc_index, i]\n",
    "\n",
    "print(denominator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffb380",
   "metadata": {},
   "source": [
    "#### Putting it all together \n",
    "\n",
    "With all the formulas worked out we can build out the entire new scaled glove vectors. Starting with the functions for the numerator and denominator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40580ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_embedding(doc_index):\n",
    "    embedding_dim = len(next(iter(glove_vectors.values())))\n",
    "    numerator = np.zeros(embedding_dim)\n",
    "    denominator = 0\n",
    "    \n",
    "    for i, word in enumerate(tfidf_matrix.columns):\n",
    "        tfidf_weight = tfidf_matrix.iloc[doc_index, i]\n",
    "        if word in glove_vectors:\n",
    "            numerator += glove_vectors[word] * tfidf_weight\n",
    "            denominator += tfidf_weight\n",
    "\n",
    "    if denominator == 0:\n",
    "        return None  # No valid words found\n",
    "\n",
    "    return (numerator / denominator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df716dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bible_1 - 0.17761724519733935 0.19172702150919133 -0.1588088226980624 -0.21498292903986915 -0.10478343759908537 -0.10890937016191478 -0.262481471138899 -0.06842042728985848 0.19763701778020346 0.07387208683620305 0.24604789124950907 0.056566160329646974 0.02069823280339885 -0.014188097661828963 -0.10265480417653812 -0.10889876285331358 -0.07679613602007046 -0.1791617848928316 0.049074593277233215 0.23752586651340654 0.13066029410326307 -0.14268302894309087 0.32724163954207103 -0.16679608784206001 -0.11650609544541417 0.21377343018774894 -0.08235621995542221 -0.07230515428367379 -0.03182007277816203 0.1824454332461255 0.01914470556371395 -0.13057780589662063 -0.17454480038778053 0.06876338611076858 -0.22509992046927355 0.059402760221710385 0.25161406218718274 0.09405823865929523 -0.15426394435529858 -0.031466708250792064 0.31414882404018124 0.0435101106879408 0.07338756735009534 0.1179685656217934 0.015331359496052138 0.0034482592495688347 -0.010254204072948674 -0.09845612747479941 -0.21761550375258304 0.04388482631552687 0.07147292351752485 0.059008883784004054 -0.11292493736539166 0.1358896362188194 0.023110656324024186 -0.09950910297456977 0.1165718940644094 -0.05514611594342326 -0.10433287292713257 0.238026519280034 0.010807951629072334 0.040332112691465076 0.09045180660652906 0.13956902624109857 0.09118468023415242 0.04929850499890018 -0.2165421688201419 -0.07773526733687686 -0.0008545142496433187 -0.16379059431106982 -0.0013148655870125715 -0.1346602491322265 0.09343526348378992 -0.042560386461584936 -0.06717952955053529 -0.10820206911898096 -0.06056761205342839 -0.03534482161257576 -0.18249541724586027 0.08707672792732085 0.1468154570527993 -0.037214562162338066 -0.05144839597043493 -0.037752172738879534 -0.23869366263069927 -0.10628983496015075 0.06647675612212994 -0.12140946139917196 -0.012592258954813279 0.02433459400421972 0.12132463875090882 0.017179964385552828 -0.032369677033001004 0.018085339747826373 -0.3380481856299364 0.1845378830755634 0.25922573018739725 0.07236569140199747 0.2004947216972826 -0.03150783276285675\n",
      "Psalter_2 - 0.11735200731835069 -0.047875898680468265 -0.022061027087685335 0.02109899053751769 -0.06820773167562967 0.0882418768401963 0.04951888481285295 -0.09828002987756372 0.01630766848622915 -0.015049058765349878 0.09034639045625528 0.0025219346723900416 0.005740122897423636 0.02379648456543218 -0.024317708142875944 -0.10489032102783744 -0.08986681070814291 -0.056223662083455576 0.015240160291226008 0.14519815382851423 0.22364671424585003 -0.211361051294274 0.06971240342999178 -0.1704288910743702 0.04641800970556177 0.1399812663067385 -0.012684719856543776 0.04265267065895168 -0.007563875482421962 0.051204874128000975 0.05865265927309232 -0.2523050910581292 -0.09778377325196606 0.13505357353134986 -0.10843933837780109 0.1128086693830082 0.20851253342901507 0.06069576930979898 0.03212026337680713 -0.10253108047977472 0.10247427359808449 0.026060813734386238 0.13479181867553888 0.20516070550463464 0.04188170293406511 0.16101075579019175 0.02591189471484863 -0.1911826855890328 -0.04215718182501933 0.03500333382581637 0.08651359061702889 0.025001016824290942 0.0401998245637477 0.1666996107787916 0.16339624375369546 0.03517091946803787 0.015415824815805775 -0.08663747221943359 -0.031169167834185826 0.050332323076191184 -0.03286769394697012 0.07961896473843749 -0.047606205356614445 0.13869891618381786 -0.0568816563444795 -0.03251850584112047 0.05480882649318133 -0.003795996345933205 0.007343256784126775 -0.08861806193813568 -0.034593812101647387 -0.21990011145156824 0.03341375421165079 -0.023041377528964055 0.030895224477620026 -0.09044956499673888 0.10509970630943875 0.1098337761324775 -0.08991194654832785 0.17990907594418085 0.07538536426933423 -0.07227851762623287 0.0727712839815498 -0.06292231121790057 -0.11935196580945868 -0.0938034766605981 0.04548459343233038 -0.0021773014176049528 -0.0056817364586197565 -0.0002542036526657141 -0.010345444630549617 -0.0707882473282779 0.03372291309610718 0.020526479884065897 -0.13753903904542825 0.08854161532482423 0.09392348313599792 0.0923244421311678 0.07212916853530606 -0.01736120400470105\n"
     ]
    }
   ],
   "source": [
    "def compute_doc_embedding(doc_index):\n",
    "    embedding_dim = len(next(iter(glove_vectors.values())))\n",
    "    numerator = np.zeros(embedding_dim)\n",
    "    denominator = 0\n",
    "    \n",
    "    for i, word in enumerate(tfidf_matrix.columns):\n",
    "        tfidf_weight = tfidf_matrix.iloc[doc_index, i]\n",
    "        if word in glove_vectors:\n",
    "            numerator += glove_vectors[word] * tfidf_weight\n",
    "            denominator += tfidf_weight\n",
    "\n",
    "    if denominator == 0:\n",
    "        return None  # No valid words found\n",
    "\n",
    "    doc_vector = numerator / denominator\n",
    "\n",
    "    # format like GloVe: \"doc_0 val1 val2 val3 ...\"\n",
    "    vector_str = \" \".join(str(x) for x in doc_vector)\n",
    "\n",
    "    # Defining the Correct Document\n",
    "    psalm_name = \"\"\n",
    "    doc_index += 1\n",
    "    if doc_index < 152:\n",
    "        psalm_name = \"Bible_\" + str(doc_index)\n",
    "    else:\n",
    "        psalm_name = \"Psalter_\" + str(doc_index-151)\n",
    "\n",
    "\n",
    "    return f\"{psalm_name} - {vector_str}\"\n",
    "\n",
    "print(compute_doc_embedding(0))\n",
    "print(compute_doc_embedding(152))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5dc8ab",
   "metadata": {},
   "source": [
    "# Building the vectors \n",
    "\n",
    "With everything impleneted. I need to builod the vectors and then begin the searching for them both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bd6dbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/caden/st_david-s-beacon/website/scripts/fall 2025'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0de4474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/scaled_glove/documents.txt\", \"w\") as file:\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        scaled_vector = compute_doc_embedding(i)\n",
    "        file.write(compute_doc_embedding(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3fb05",
   "metadata": {},
   "source": [
    "Building the searching Algorithm\n",
    "\n",
    "In order to do this, we need to addapt the function build to be able to take in a query from the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "347bd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = {}\n",
    "with open(\"data/scaled_glove/documents.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 2:\n",
    "            continue  # skip empty or malformed lines\n",
    "\n",
    "        doc_id = parts[0]  # keep as string\n",
    "        vector = []\n",
    "        for x in parts[1:]:\n",
    "            try:\n",
    "                vector.append(float(x))\n",
    "            except ValueError:\n",
    "                # skip invalid entries (like stray '-')\n",
    "                continue\n",
    "\n",
    "        if vector:\n",
    "            doc_embeddings[doc_id] = np.array(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d48035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of documents\n",
    "N = tfidf_matrix.shape[0]\n",
    "\n",
    "# Count how many docs contain each word\n",
    "df = np.sum(tfidf_matrix > 0, axis=0)  # document frequency\n",
    "\n",
    "# Compute IDF\n",
    "idf_weights = np.log((N + 1) / (df + 1)) + 1  # standard smoothed IDF\n",
    "\n",
    "# Map to dict\n",
    "idf_weights = dict(zip(tfidf_matrix.columns, idf_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d141ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64787843,  0.34724888, -0.13749125, -0.5295998 , -0.31645602,\n",
       "        0.47254025, -0.18642918,  0.27779908,  0.27535727, -0.19321665,\n",
       "       -0.01174244,  0.39726597,  0.10776291, -0.29093236,  0.39399376,\n",
       "       -0.61447646,  0.02014442, -0.21058776, -0.34409186, -0.42060957,\n",
       "        0.3487609 , -0.35851556, -0.18471329,  0.1325755 , -0.41463634,\n",
       "        0.08261808, -0.37124458, -0.01912455, -0.14104153, -0.42184289,\n",
       "       -0.02653087, -0.62453996,  0.24128471, -0.39792396, -0.21040233,\n",
       "        0.35035072,  0.41500063,  0.14163404, -0.12483954, -0.40547497,\n",
       "        0.33063646,  0.63134996,  0.13957369,  0.05756844,  0.17275259,\n",
       "        0.52924231,  0.5566496 , -0.06621642,  0.01233958, -0.40780436,\n",
       "        0.70788011, -0.22479976, -0.05356337,  0.16438683,  0.32632553,\n",
       "       -0.67026823, -0.47685989, -0.06755063, -1.09800653, -0.2085664 ,\n",
       "       -0.40213917, -0.15021882,  0.27804953, -0.0271095 , -0.29770133,\n",
       "       -0.3014342 ,  0.51739821, -0.19454413, -0.2046976 ,  0.26667449,\n",
       "       -0.06658998, -0.19559666, -0.20828259,  0.27614722, -0.03428186,\n",
       "       -0.13220901,  0.33382729,  0.34092592, -0.10663791,  0.11465719,\n",
       "        0.66121851, -0.21371766, -0.06499234, -0.38032531, -0.2008973 ,\n",
       "       -0.32823481, -0.1869897 ,  0.60743593, -0.36585099, -0.69632611,\n",
       "        0.34720018, -0.21224325,  0.16808323, -0.44880803,  0.20376538,\n",
       "       -0.21849084,  0.37322452, -0.05308041, -0.53128706, -0.00883215])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_query_embedding(query):\n",
    "    tokens = query.lower().split()  # lowercase, remove punctuation, tokenize\n",
    "    \n",
    "    numerator = np.zeros(embedding_dim)\n",
    "    denominator = 0\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in glove_vectors and word in idf_weights:\n",
    "            weight = idf_weights[word]  # or full TF-IDF if TF available\n",
    "            numerator += glove_vectors[word] * weight\n",
    "            denominator += weight\n",
    "\n",
    "    if denominator == 0:\n",
    "        return None\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "compute_query_embedding(\"For the Peace of the World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4dd1d662",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doc_embeddings[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "doc_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    q_vec = compute_query_embedding(query)\n",
    "\n",
    "    print(q_vec)\n",
    "    \n",
    "    results = []\n",
    "    for _, row in doc_embeddings.iterrows():\n",
    "        sim = np.dot(q_vec, row['glove_vec']) / (np.linalg.norm(q_vec) * np.linalg.norm(row['glove_vec']))\n",
    "        results.append({\n",
    "            \"doc\": row['text'],\n",
    "            \"psalm_num\": row['psalm_num'],\n",
    "            \"psalm\": row['psalm'],\n",
    "            \"similarity\": round(sim*100, 2)\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity\n",
    "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    return results[:6]  # top 6 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb27cc",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "665467b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "word_embed() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tfidf_matrix\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m word_embed(tfidf_matrix\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: word_embed() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "tfidf_matrix.columns[0]\n",
    "\n",
    "word_embed(tfidf_matrix.columns[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423feeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32430e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/scaled_glove/vocab.txt\", \"w\") as file:\n",
    "    for i in range(tfidf_matrix.shape[1]):\n",
    "        word = tfidf_matrix.column s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
