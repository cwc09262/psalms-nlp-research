{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213f6adf",
   "metadata": {},
   "source": [
    "# Logging Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282662f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_top_matches(query, model_name, top_indices, similarities, full_psalms, filename=\"query_results.txt\"):\n",
    "    \"\"\"\n",
    "    Write the top psalm matches to a results file (and print them).\n",
    "    Includes the original query and model information as a heading.\n",
    "    \"\"\"\n",
    "    output_lines = []\n",
    "    output_lines.append(\"=\" * 80)\n",
    "    output_lines.append(f\"Query: {query}\")\n",
    "    output_lines.append(f\"Model: {model_name}\")\n",
    "    output_lines.append(\"Top 5 matching psalms:\")\n",
    "\n",
    "    line_length = 125\n",
    "\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        text_type = \"Bible\" if idx <= 151 else \"Psalter\"\n",
    "        num = idx if idx <= 151 else idx - 151\n",
    "        psalm = full_psalms.iloc[idx]['verse']\n",
    "        formatted_verse = \"\"\n",
    "        # split into lines of length `line_length`\n",
    "        for i in range(0, len(text), line_length):\n",
    "            formatted_verse += psalm[i:i+line_length] + \"\\n\"\n",
    "\n",
    "        line = (\n",
    "            f\"{rank}. {text_type} Psalm {num + 1} - Similarity: {similarities[idx]}%\\n\"\n",
    "            f\"{formatted_verse}\\n\"\n",
    "        )\n",
    "        output_lines.append(line)\n",
    "\n",
    "    # Combine into one result block\n",
    "    result_block = \"\\n\".join(output_lines)\n",
    "\n",
    "    # Print to console\n",
    "    print(result_block)\n",
    "\n",
    "    # Append to a file\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_block + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e6abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978a7ae1",
   "metadata": {},
   "source": [
    "# GLoVe X TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e84bbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/psalms_with_vectors.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m psalms \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/psalms_with_vectors.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/psalms_with_vectors.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "psalms = pd.read_csv(\"data/psalms_with_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "psalms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = {}\n",
    "\n",
    "with open(\"word_embeddings/vectors.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()        # split by spaces\n",
    "        word = parts[0]                     # first part is the word\n",
    "        vector = [float(x) for x in parts[1:]]  # rest are floats\n",
    "        glove_vectors[word] = vector\n",
    "\n",
    "\n",
    "# glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1545b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = len(next(iter(glove_vectors.values())))  # get embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a625129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# getting the pickle file ready to be used\n",
    "with open(\"../../data/models/psalms_tfidf_matrix.pickle\", \"rb\") as file:\n",
    "    tfidf_matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddce119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents\n",
    "N = tfidf_matrix.shape[0]\n",
    "\n",
    "# Count how many docs contain each word\n",
    "df = np.sum(tfidf_matrix > 0, axis=0)  # document frequency\n",
    "\n",
    "# Compute IDF\n",
    "idf_weights = np.log((N + 1) / (df + 1)) + 1  # standard smoothed IDF\n",
    "\n",
    "# Map to dict\n",
    "idf_weights = dict(zip(tfidf_matrix.columns, idf_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_query_embedding(query):\n",
    "    tokens = query.lower().split()  # lowercase, remove punctuation, tokenize\n",
    "    \n",
    "    numerator = np.zeros(embedding_dim)\n",
    "    denominator = 0\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in glove_vectors and word in idf_weights:\n",
    "            weight = idf_weights[word]  # or full TF-IDF if TF available\n",
    "            numerator += glove_vectors[word] * weight\n",
    "            denominator += weight\n",
    "\n",
    "    if denominator == 0:\n",
    "        return None\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ensure_array(x):\n",
    "    if isinstance(x, str):\n",
    "        # string like \"[0.04116335 -0.16281123 ...]\"\n",
    "        x = x.strip(\"[]\")  # remove brackets\n",
    "        numbers = [float(n) for n in x.split()]\n",
    "        return np.array(numbers, dtype=float)\n",
    "    elif isinstance(x, list):\n",
    "        # list -> array\n",
    "        return np.array(x, dtype=float)\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        # already array, do nothing\n",
    "        return x\n",
    "    else:\n",
    "        # fallback to zero vector if something else\n",
    "        return np.zeros(300)  # replace 300 with your embedding_dim\n",
    "\n",
    "psalms[\"glove_tfidf_vec\"] = psalms[\"glove_tfidf_vec\"].apply(ensure_array)\n",
    "\n",
    "# Check\n",
    "print(type(psalms[\"glove_tfidf_vec\"].iloc[0]))  # <class 'numpy.ndarray'>\n",
    "print(psalms[\"glove_tfidf_vec\"].iloc[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check\n",
    "print(type(psalms[\"glove_tfidf_vec\"].iloc[0]))  # should be <class 'numpy.ndarray'>\n",
    "print(psalms[\"glove_tfidf_vec\"].iloc[0].shape)  # should show (embedding_dim,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(psalms[\"glove_tfidf_vec\"].iloc[0]))  # <class 'numpy.ndarray'>\n",
    "print(psalms[\"glove_tfidf_vec\"].iloc[0].shape)  # e.g., (300,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for word in glove_vectors:\n",
    "    glove_vectors[word] = np.array(glove_vectors[word], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tfidf_glove(query, top_k=6):\n",
    "    # Compute query embedding\n",
    "    q_vec = compute_query_embedding(query)\n",
    "    if q_vec is None:\n",
    "        return []  # return empty list if no valid words in query\n",
    "\n",
    "    # Precompute query norm once\n",
    "    q_norm = np.linalg.norm(q_vec)\n",
    "    if q_norm == 0:\n",
    "        return []\n",
    "\n",
    "    sims = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for idx, row in psalms.iterrows():\n",
    "        doc_vec = row['glove_tfidf_vec']\n",
    "        doc_norm = np.linalg.norm(doc_vec)\n",
    "        if doc_norm == 0:\n",
    "            continue  # skip empty embeddings\n",
    "\n",
    "        # Cosine similarity\n",
    "        sim = np.dot(q_vec, doc_vec) / (q_norm * doc_norm)\n",
    "        sims.append((idx, round(sim*100, 2)))  # store index and similarity\n",
    "\n",
    "    # Sort by similarity in descending order\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_indices = [(\"TFIDF_GLoVe\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "    \n",
    "    return (top_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26388615",
   "metadata": {},
   "source": [
    "## Testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"For the Peace of the World\"\n",
    "\n",
    "(query_tfidf_glove(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc7182",
   "metadata": {},
   "source": [
    "# BERT & SBERT\n",
    "\n",
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "output_dir = \"data/bert\"\n",
    "psalm_embeddings = []\n",
    "\n",
    "# Load all saved embeddings\n",
    "for filename in sorted(os.listdir(output_dir)):\n",
    "    if filename.endswith(\".npy\") and \"psalm_\" in filename:\n",
    "        emb = np.load(os.path.join(output_dir, filename))\n",
    "        psalm_embeddings.append(emb)\n",
    "\n",
    "psalm_embeddings = np.stack(psalm_embeddings)  # shape: (num_psalms, 768)\n",
    "print(\"Loaded psalm embeddings:\", psalm_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean Psalm Encoder using BERT ---\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2️⃣ Load tokenizer and model (fresh instances)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert_model.eval()  # evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881469e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_bert(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encode a single text string into a 1D numpy array (hidden_size,)\n",
    "    Uses attention-mask weighted mean to ignore padding.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Move inputs to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)  # last_hidden_state: (1, seq_len, hidden)\n",
    "        hidden = outputs.last_hidden_state\n",
    "        mask = inputs.get(\"attention_mask\")\n",
    "        \n",
    "        if mask is None:\n",
    "            pooled = hidden.mean(dim=1)\n",
    "        else:\n",
    "            mask = mask.unsqueeze(-1)  # (1, seq_len, 1)\n",
    "            masked_hidden = hidden * mask\n",
    "            summed = masked_hidden.sum(dim=1)\n",
    "            counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "            pooled = summed / counts\n",
    "    \n",
    "    return pooled.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two 1D numpy arrays.\"\"\"\n",
    "    a_norm = a / np.linalg.norm(a)\n",
    "    b_norm = b / np.linalg.norm(b)\n",
    "    return float(np.dot(a_norm, b_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bert(query, top_k=5):\n",
    "\n",
    "    print(\"BERT Query: \", query)\n",
    "\n",
    "    if not query:\n",
    "        print(\"Empty query. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # 1. Encode query with BERT\n",
    "    query_emb = encode_text_bert(query)\n",
    "\n",
    "    # 2. Compute similarities\n",
    "    similarities = []\n",
    "    for i, psalm_emb in enumerate(psalm_embeddings):\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, round(sim * 100, 2)))  # store index + sim %\n",
    "\n",
    "    # 3. Sort by similarity descending\n",
    "    sims = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "\n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_results = [(\"BERT\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "\n",
    "\n",
    "    return (top_results)\n",
    "\n",
    "    # 4. Log matches (and write to file)\n",
    "    ''' log_top_matches(query,\n",
    "        model_name=\"BERT\",\n",
    "        top_indices=top_indices,\n",
    "        similarities=similarities,\n",
    "        full_psalms=full_psalms,\n",
    "    )'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3713dbb",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a55cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(query_bert(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fefb8c",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use a pretrained SBERT model\n",
    "sbert_model = SentenceTransformer('all-mpnet-base-v2')  # or any SBERT variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "utput_dir = \"data/sbert\"\n",
    "psalm_SBERT_embeddings = []\n",
    "\n",
    "# Load all saved embeddings\n",
    "for filename in sorted(os.listdir(output_dir)):\n",
    "    if filename.endswith(\".npy\") and \"psalm_\" in filename:\n",
    "        emb = np.load(os.path.join(output_dir, filename))\n",
    "        psalm_SBERT_embeddings.append(emb)\n",
    "\n",
    "psalm_SBERT_embeddings = np.stack(psalm_SBERT_embeddings)  # shape: (num_psalms, 768)\n",
    "print(\"Loaded psalm embeddings:\", psalm_SBERT_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_SBERT(text):\n",
    "    return sbert_model.encode(text, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sbert(query, top_k=5):\n",
    "    print(\"Query: \", query)\n",
    "\n",
    "    if not query:\n",
    "        print(\"Empty query. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    query_emb = encode_text_SBERT(query)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for i, psalm_emb in enumerate(psalm_SBERT_embeddings):\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, round(sim*100, 2)))\n",
    "\n",
    "    \n",
    "    # 3. Sort by similarity descending\n",
    "    sims = sorted(similarities, reverse=True)[:5]\n",
    "    \n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_results = [(\"SBERT\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "\n",
    "    # Checking the Output\n",
    "    return (top_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9d680",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39287e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_sbert(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ace31d",
   "metadata": {},
   "source": [
    "#### Comparing Embedding sizes\n",
    "\n",
    "I am getting very low similarity percentages for `SBERT` results compared to `BERT` results. There are a few things that may be contributing to this. One of them may have to do with the different dimensions of embeddings between `BERT` & `SBERT`. Let look at that first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BERT Embeddings: {psalm_embeddings.shape}\")\n",
    "print(f\"SBERT Embeddings: {psalm_SBERT_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc2c7d",
   "metadata": {},
   "source": [
    "The dimensions for both are the same, therefore the problems seems like i t lies within the `SBERT` algorithm itself. Lets look at the embeddings for `SBERT` closer and see what is happening. We are going to look at the embeddings right before the cosine similarity is calculated and see if there are any negatives within the embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c000035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sbert(query, top_k=5):\n",
    "    print(\"Query: \", query)\n",
    "\n",
    "    if not query:\n",
    "        print(\"Empty query. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    query_emb = encode_text_SBERT(query)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for i, psalm_emb in enumerate(psalm_SBERT_embeddings):\n",
    "        print(f\"Query: {query_emb} \\n Emedding: {psalm_emb}\")\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, round(sim*100, 2)))\n",
    "\n",
    "    \n",
    "    # 3. Sort by similarity descending\n",
    "    sims = sorted(similarities, reverse=True)[:5]\n",
    "    \n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_indices = [(\"SBERT\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "\n",
    "    # Checking the Output\n",
    "    print(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61811b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_sbert(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5abed",
   "metadata": {},
   "source": [
    "It can be seen that there are negative values within the embeddings and because of this it is interfereing with the score and making them seem lower than they actually are. We can write a simple sunction to basically shift all of the embedding to be strictly **positive**, which should fix the off balance of similarity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_embedding(embedding):\n",
    "    min_val = embedding.min()\n",
    "    shifted = embedding - min_val\n",
    "\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae924328",
   "metadata": {},
   "source": [
    "We can now apply this to the embeddings themselves and then look at the similarities again and see if this affected the similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psalm_SBERT_embeddings = shift_embedding(psalm_SBERT_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sbert(query, top_k=5):\n",
    "    print(\"Query: \", query)\n",
    "\n",
    "    if not query:\n",
    "        print(\"Empty query. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    query_emb = encode_text_SBERT(query)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    # Shifting the Embeddings\n",
    "    query_emb = shift_embedding(query_emb)\n",
    "    #psalm_SBERT_embeddings = shift_embedding(psalm_SBERT_embeddings)\n",
    "\n",
    "    for i, psalm_emb in enumerate(psalm_SBERT_embeddings):\n",
    "        print(f\"Query: {query_emb} \\n Emedding: {psalm_emb}\")\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, round(sim*100, 2)))\n",
    "\n",
    "    \n",
    "    # 3. Sort by similarity descending\n",
    "    sims = sorted(similarities, reverse=True)[:5]\n",
    "    \n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_indices = [(\"SBERT\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "\n",
    "    # Checking the Output\n",
    "    print(top_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c706e26",
   "metadata": {},
   "source": [
    "Let's run the same query again and see if there are different results given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_sbert(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad712e",
   "metadata": {},
   "source": [
    "All of our embeddings are no2w strictly positive. lets run the query now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdc9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sbert(query, top_k=5):\n",
    "    print(\"Query: \", query)\n",
    "\n",
    "    if not query:\n",
    "        print(\"Empty query. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    query_emb = encode_text_SBERT(query)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    # Shifting the Embeddings\n",
    "    query_emb = shift_embedding(query_emb)\n",
    "    #psalm_SBERT_embeddings = shift_embedding(psalm_SBERT_embeddings)\n",
    "\n",
    "    for i, psalm_emb in enumerate(psalm_SBERT_embeddings):\n",
    "        #print(f\"Query: {query_emb} \\n Emedding: {psalm_emb}\")\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, round(sim*100, 2)))\n",
    "\n",
    "    \n",
    "    # 3. Sort by similarity descending\n",
    "    sims = sorted(similarities, reverse=True)[:5]\n",
    "    \n",
    "\n",
    "    # Return the top_k indices\n",
    "    top_indices = [(\"SBERT\", idx,sim) for idx, sim in sims[:top_k]]\n",
    "\n",
    "    # Checking the Output\n",
    "    return (top_indices)\n",
    "\n",
    "query_sbert(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce567687",
   "metadata": {},
   "source": [
    "With the embeddings a shfited, we are now getting really high similarities which could be a good thing. Lets now update the `cosine_similarity()` function to handle the shifting as all three algorithms are using this to compare and gather results. We are going to take the shifting out of the SBERT algorithm first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d020cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sbert(query, top_k=5):\n",
    "    query_emb = encode_text_SBERT(query)\n",
    "\n",
    "    similarities = []\n",
    "    for i, psalm_emb in enumerate(psalm_SBERT_embeddings):\n",
    "        sim = cosine_similarity(query_emb, psalm_emb)\n",
    "        similarities.append((i, sim))  # store raw similarity (not scaled)\n",
    "\n",
    "    # Sort by similarity descending\n",
    "    sims = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Return (method, index, similarity%) for top_k results\n",
    "    top_indices = [(\"SBERT\", idx, round(sim * 100, 2)) for idx, sim in sims]\n",
    "\n",
    "    return top_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sbert(\"Have mercy on me, O God, have mercy on me. For my soul trusts in Thee, and in the shadow of Thy wings will I hope, until iniquity pass away.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47567483",
   "metadata": {},
   "source": [
    "Then update the `cosine_similarity()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    ''' Ensuring that both embeddings are strictly positive'''\n",
    "    if a.min() < 0:\n",
    "        a = shift_embedding(a)\n",
    "    \n",
    "    if b.min() < 0:\n",
    "        b = shift_embedding(b)\n",
    "        \n",
    "    \"\"\"Compute cosine similarity between two 1D numpy arrays.\"\"\"\n",
    "    a_norm = a / np.linalg.norm(a)\n",
    "    b_norm = b / np.linalg.norm(b)\n",
    "    return float(np.dot(a_norm, b_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415cc175",
   "metadata": {},
   "source": [
    "Now lets examine of the results of all of the algorithms together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459aa2c8",
   "metadata": {},
   "source": [
    "# Testing All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24776d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_all(q):\n",
    "    # GLoVe scaled by TF_IDF \n",
    "    (query_tfidf_glove(q))\n",
    "    # BERT\n",
    "    query_bert(q)\n",
    "    # SBERT\n",
    "    query_sbert(q)\n",
    "\n",
    "print(query_all(\"For the Peace of the world\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff306ac",
   "metadata": {},
   "source": [
    "I want to be able to store ans keep track of the data generate by each of the three algorithms based on the queries. I want to store it all in a dataFrame for future analaysis\n",
    "\n",
    "## Storing Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aac45372",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = pd.DataFrame(columns= [\"Query\", \"Method\", \"Similarity Score (%)\", \"Text\", \"Psalm Num\", \"Verse\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55354d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(query, results):\n",
    "    for result in results:\n",
    "        method, index, sim = result\n",
    "        target_psalm = psalms.iloc[index]\n",
    "        text = target_psalm[\"text\"]\n",
    "        psalm_num = target_psalm[\"psalm_num\"]\n",
    "        verse = target_psalm[\"verse\"]\n",
    "\n",
    "        # Correct way to append a row\n",
    "        full_results.loc[len(full_results)] = [query, method, sim, text, psalm_num, verse]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba37daa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_tfidf_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# SBERT\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     record_results(q, query_sbert(q))\n\u001b[0;32m----> 9\u001b[0m query_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the Peace of the world\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m, in \u001b[0;36mquery_all\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_all\u001b[39m(q):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# GLoVe scaled by TF_IDF \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     record_results(q, query_tfidf_glove(q))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# BERT\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     record_results(q, query_bert(q))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_tfidf_glove' is not defined"
     ]
    }
   ],
   "source": [
    "def query_all(q):\n",
    "    # GLoVe scaled by TF_IDF \n",
    "    record_results(q, query_tfidf_glove(q))\n",
    "    # BERT\n",
    "    record_results(q, query_bert(q))\n",
    "    # SBERT\n",
    "    record_results(q, query_sbert(q))\n",
    "\n",
    "query_all(\"For the Peace of the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97646631",
   "metadata": {},
   "source": [
    "# Graphing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(full_results['Psalm Num'], full_results[\"Similarity Score (%)\"])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd093eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=full_results,\n",
    "    x=\"Psalm Num\",\n",
    "    y=\"Similarity Score (%)\",\n",
    "    hue=\"Text\",       # color by text\n",
    "    size=\"Method\",    # scale by method\n",
    "    palette=\"viridis\",\n",
    "    sizes=(40, 200),\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"k\"\n",
    ")\n",
    "\n",
    "plt.title(f\"Psalm Similarity by Text and Method \\n Based on the Query: {query}\")\n",
    "#plt.suptitle(f\"Based on the Query: {query}\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a573808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for the graping\n",
    "def graph_results(results):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        data=results,\n",
    "        x=\"Psalm Num\",\n",
    "        y=\"Similarity Score (%)\",\n",
    "        hue=\"Text\",       # color by text\n",
    "        size=\"Method\",    # scale by method\n",
    "        palette=\"viridis\",\n",
    "        sizes=(40, 200),\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    line\n",
    "\n",
    "    query = textwrap.fill(results.iloc[0][\"Query\"], width=60)\n",
    "\n",
    "    plt.title(f\"Psalm Similarity by Text and Method \\n Based on the Query: {query}\")\n",
    "    #plt.suptitle(f\"Based on the Query: {query}\")\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003691e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_results(full_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba2ae4",
   "metadata": {},
   "source": [
    "With everything needed to implents some investigations, lets work on runing a bunch of different queries to be able to look for any trends that may emerge. After a little thought and consulting ChatGPT I am going to use the following queries to test on all three of the algorithms. \n",
    "### Psalms Search Test Queries\n",
    "\n",
    "#### 1. Simple Keyword Queries\n",
    "- **Query 1:** mercy\n",
    "\n",
    "#### 2. Phrase/Exact Match Queries\n",
    "- **Query 2:** The Lord is my shepherd\n",
    "\n",
    "#### 3. Thematic/Semantic Queries\n",
    "- **Query 3:** protection from enemies\n",
    "- **Query 4:** praise in times of suffering\n",
    "\n",
    "#### 4. Long/Complex Queries\n",
    "- **Query 5:** How does the psalmist express trust in God while surrounded by fear and uncertainty?\n",
    "- **Query 6:** Verses where the psalmist remembers past deliverance and uses it to find hope in present trials.\n",
    "\n",
    "#### 5. Orthodox Service Quotes\n",
    "##### From *Vespers*\n",
    "- **Query 7:** \n",
    "    >\"Rejoice, O ye heavens, sound the trumpets, ye foundation of the earth, thunder forth gladness, O ye mountains: for behold, Emanuel to    the Cross our sins, and the Giver of Life hath slain death, rasing up Adam,; for He loveth man kind.\"\n",
    "\n",
    "- **Query 8:**\n",
    "    >\"“Have mercy on me, O God, have mercy on me. For my soul trusts in Thee, and in the shadow of Thy wings will I hope, until iniquity pass away.”\n",
    "\n",
    "We can now store all of these within a dictionary to organize them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psalm_queries.py (you can save this to import later)\n",
    "queries = [\n",
    "    # 1. Simple Keyword Queries\n",
    "    {\"id\": 1, \"category\": \"Simple Keyword\", \"text\": \"mercy\"},\n",
    "\n",
    "    # 2. Phrase/Exact Match Queries\n",
    "    {\"id\": 2, \"category\": \"Phrase/Exact Match\", \"text\": \"The Lord is my shepherd\"},\n",
    "\n",
    "    # 3. Thematic/Semantic Queries\n",
    "    {\"id\": 3, \"category\": \"Thematic/Semantic\", \"text\": \"protection from enemies\"},\n",
    "    {\"id\": 4, \"category\": \"Thematic/Semantic\", \"text\": \"praise in times of suffering\"},\n",
    "\n",
    "    # 4. Long/Complex Queries\n",
    "    {\"id\": 5, \"category\": \"Long/Complex\", \n",
    "     \"text\": \"How does the psalmist express trust in God while surrounded by fear and uncertainty?\"},\n",
    "    {\"id\": 6, \"category\": \"Long/Complex\", \n",
    "     \"text\": \"Verses where the psalmist remembers past deliverance and uses it to find hope in present trials.\"},\n",
    "\n",
    "    # 5. Orthodox Service Quotes\n",
    "    {\"id\": 7, \"category\": \"Orthodox Service (Vespers)\", \n",
    "     \"text\": \"Rejoice, O ye heavens, sound the trumpets, ye foundation of the earth, thunder forth gladness, O ye mountains: for behold, Emmanuel to the Cross our sins, and the Giver of Life hath slain death, raising up Adam; for He loveth mankind.\"},\n",
    "\n",
    "    {\"id\": 8, \"category\": \"Orthodox Service: Great Canon of St. Andrew of Crete \", \n",
    "     \"text\": \"Have mercy on me, O God, have mercy on me. For my soul trusts in Thee, and in the shadow of Thy wings will I hope, until iniquity pass away.\"}\n",
    "]\n",
    "\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280996e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in queries:\n",
    "    query_all(q['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure Pandas display options\n",
    "pd.set_option('display.max_rows', 50)       # show all rows\n",
    "pd.set_option('display.max_columns', None)    # show all columns\n",
    "pd.set_option('display.max_colwidth', 180)   # don't truncate text\n",
    "pd.set_option('display.expand_frame_repr', False)  # keep wide frames on one line\n",
    "\n",
    "# Then simply display the DataFrame\n",
    "full_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_queries = full_results.groupby(\"Query\")\n",
    "\n",
    "grouped_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q, group in grouped_queries:\n",
    "    graph_results(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_results(full_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_results.to_csv(\"full_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9c737",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "After an intail set of scoring and seeing some results, it was decided it might be useful to just see `TF-IDF` as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0784a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3369c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "MODEL_PATH = os.path.abspath(\n",
    "    os.path.join(\n",
    "        cwd,\n",
    "        \"..\",\n",
    "        \"data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "with open(MODEL_PATH +\"/psalms_tfidf_matrix.pickle\", \"rb\") as f:\n",
    "    tfidf_matrix = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(MODEL_PATH +\"/psalms_tfidf_vectorizer.pickle\", \"rb\") as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "with open(MODEL_PATH +\"/grouped_psalm.csv\", \"rb\") as f:\n",
    "    psalms = pd.read_csv(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c69439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tradition</th>\n",
       "      <th>text</th>\n",
       "      <th>psalm_num</th>\n",
       "      <th>verse</th>\n",
       "      <th>cleaned_verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Bible</td>\n",
       "      <td>1</td>\n",
       "      <td>Blessed is the man Who walks not in the counse...</td>\n",
       "      <td>blessed man walk counsel ungodly stand way sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Bible</td>\n",
       "      <td>2</td>\n",
       "      <td>Why do the nations rage And the people meditat...</td>\n",
       "      <td>nation rage people meditate vain thing king ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Bible</td>\n",
       "      <td>3</td>\n",
       "      <td>A psalm by David when he fled from the face of...</td>\n",
       "      <td>psalm david fled face son absalom olord afflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Bible</td>\n",
       "      <td>4</td>\n",
       "      <td>For the End in psalms an ode by David You hear...</td>\n",
       "      <td>end psalm ode david heard icalled god righteou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Bible</td>\n",
       "      <td>5</td>\n",
       "      <td>For the End concerning the inheritance a psalm...</td>\n",
       "      <td>end concerning inheritance psalm david give ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>146</td>\n",
       "      <td>The Lord doth build up Jerusalem; He shall gat...</td>\n",
       "      <td>lord doth build jerusalem ; shall gather toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>147</td>\n",
       "      <td>Praise the Lord, O Jerusalem; praise thy God, ...</td>\n",
       "      <td>praise lord , jerusalem ; praise thy god , zio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>148</td>\n",
       "      <td>Praise ye the Lord from the heavens; praise Hi...</td>\n",
       "      <td>praise ye lord heaven ; praise highest . prais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>149</td>\n",
       "      <td>Sing unto the Lord a new song, His praise is i...</td>\n",
       "      <td>sing unto lord new song , praise congregation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>150</td>\n",
       "      <td>Praise God in His holy ones; praise Him in the...</td>\n",
       "      <td>praise god holy one ; praise firmament power ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 tradition     text  psalm_num  \\\n",
       "0             0  Orthodox    Bible          1   \n",
       "1             1  Orthodox    Bible          2   \n",
       "2             2  Orthodox    Bible          3   \n",
       "3             3  Orthodox    Bible          4   \n",
       "4             4  Orthodox    Bible          5   \n",
       "..          ...       ...      ...        ...   \n",
       "296         296  Orthodox  Psalter        146   \n",
       "297         297  Orthodox  Psalter        147   \n",
       "298         298  Orthodox  Psalter        148   \n",
       "299         299  Orthodox  Psalter        149   \n",
       "300         300  Orthodox  Psalter        150   \n",
       "\n",
       "                                                 verse  \\\n",
       "0    Blessed is the man Who walks not in the counse...   \n",
       "1    Why do the nations rage And the people meditat...   \n",
       "2    A psalm by David when he fled from the face of...   \n",
       "3    For the End in psalms an ode by David You hear...   \n",
       "4    For the End concerning the inheritance a psalm...   \n",
       "..                                                 ...   \n",
       "296  The Lord doth build up Jerusalem; He shall gat...   \n",
       "297  Praise the Lord, O Jerusalem; praise thy God, ...   \n",
       "298  Praise ye the Lord from the heavens; praise Hi...   \n",
       "299  Sing unto the Lord a new song, His praise is i...   \n",
       "300  Praise God in His holy ones; praise Him in the...   \n",
       "\n",
       "                                         cleaned_verse  \n",
       "0    blessed man walk counsel ungodly stand way sin...  \n",
       "1    nation rage people meditate vain thing king ea...  \n",
       "2    psalm david fled face son absalom olord afflic...  \n",
       "3    end psalm ode david heard icalled god righteou...  \n",
       "4    end concerning inheritance psalm david give ea...  \n",
       "..                                                 ...  \n",
       "296  lord doth build jerusalem ; shall gather toget...  \n",
       "297  praise lord , jerusalem ; praise thy god , zio...  \n",
       "298  praise ye lord heaven ; praise highest . prais...  \n",
       "299  sing unto lord new song , praise congregation ...  \n",
       "300  praise god holy one ; praise firmament power ....  \n",
       "\n",
       "[301 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psalms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "766e0fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d086cfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abasement</th>\n",
       "      <th>abated</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abhorred</th>\n",
       "      <th>abhors</th>\n",
       "      <th>abide</th>\n",
       "      <th>abides</th>\n",
       "      <th>abideth</th>\n",
       "      <th>...</th>\n",
       "      <th>zacharias</th>\n",
       "      <th>zalmon</th>\n",
       "      <th>zalmunna</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zebah</th>\n",
       "      <th>zebulun</th>\n",
       "      <th>zeeb</th>\n",
       "      <th>zion</th>\n",
       "      <th>ziphites</th>\n",
       "      <th>zoan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Bible, 1)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 2)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 3)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 4)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Bible, 5)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 146)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 147)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 148)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 149)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Psalter, 150)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 3416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                aaron  abandon  abasement  abated  abhor  abhorred    abhors  \\\n",
       "(Bible, 1)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 2)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 3)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 4)        0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Bible, 5)        0.0      0.0        0.0     0.0    0.0       0.0  0.158926   \n",
       "...               ...      ...        ...     ...    ...       ...       ...   \n",
       "(Psalter, 146)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 147)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 148)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 149)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "(Psalter, 150)    0.0      0.0        0.0     0.0    0.0       0.0  0.000000   \n",
       "\n",
       "                abide  abides  abideth  ...  zacharias  zalmon  zalmunna  \\\n",
       "(Bible, 1)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 2)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 3)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 4)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Bible, 5)        0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "...               ...     ...      ...  ...        ...     ...       ...   \n",
       "(Psalter, 146)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 147)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 148)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 149)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "(Psalter, 150)    0.0     0.0      0.0  ...        0.0     0.0       0.0   \n",
       "\n",
       "                zeal  zebah  zebulun  zeeb      zion  ziphites  zoan  \n",
       "(Bible, 1)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 2)       0.0    0.0      0.0   0.0  0.073937       0.0   0.0  \n",
       "(Bible, 3)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 4)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Bible, 5)       0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "...              ...    ...      ...   ...       ...       ...   ...  \n",
       "(Psalter, 146)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Psalter, 147)   0.0    0.0      0.0   0.0  0.072535       0.0   0.0  \n",
       "(Psalter, 148)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "(Psalter, 149)   0.0    0.0      0.0   0.0  0.077526       0.0   0.0  \n",
       "(Psalter, 150)   0.0    0.0      0.0   0.0  0.000000       0.0   0.0  \n",
       "\n",
       "[301 rows x 3416 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce7d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(query, results_df):\n",
    "    \"\"\"\n",
    "    Append query results DataFrame to full_results.\n",
    "    \"\"\"\n",
    "    for _, row in results_df.iterrows():\n",
    "        # Extract values from the row\n",
    "        method = row['Method']\n",
    "        sim = row['Similarity Score (%)']\n",
    "        text = row['Text']\n",
    "        psalm_num = row['Psalm Num']\n",
    "        verse = row['Verse']\n",
    "\n",
    "        # Append to the global full_results DataFrame\n",
    "        full_results.loc[len(full_results)] = [query, method, sim, text, psalm_num, verse]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd0731a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tfidf(query, top_k=6):\n",
    "    query_vec = tfidf_vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "\n",
    "    top_indices = sims.argsort()[::-1][:top_k]\n",
    "    top_scores = sims[top_indices] * 100  # percent\n",
    "\n",
    "    results = [(\"TF-IDF\", idx, score) for idx, score in zip(top_indices, top_scores)]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d2f5d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TF-IDF', 271, 18.675395800994878),\n",
       " ('TF-IDF', 120, 18.612013010937538),\n",
       " ('TF-IDF', 247, 15.302091583685066),\n",
       " ('TF-IDF', 96, 14.183477308107623),\n",
       " ('TF-IDF', 91, 12.570602777670539),\n",
       " ('TF-IDF', 245, 11.329991914781507)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tfidf(\"for the peace of the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "422663da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = query_tfidf(\"for the peace of the world\")\n",
    "record_results(\"for the peace of the world\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd2a8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Method</th>\n",
       "      <th>Similarity Score (%)</th>\n",
       "      <th>Text</th>\n",
       "      <th>Psalm Num</th>\n",
       "      <th>Verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>18.675396</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>121</td>\n",
       "      <td>I was glad because of them that said to me, Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>18.612013</td>\n",
       "      <td>Bible</td>\n",
       "      <td>121</td>\n",
       "      <td>1An ode of ascents Iwas glad when they said to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>15.302092</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>97</td>\n",
       "      <td>O sing unto the Lord a new song, for the Lord ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>14.183477</td>\n",
       "      <td>Bible</td>\n",
       "      <td>97</td>\n",
       "      <td>A psalm by David Sing a new song to the Lord F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>12.570603</td>\n",
       "      <td>Bible</td>\n",
       "      <td>92</td>\n",
       "      <td>1For the day before the Sabbath when the earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for the peace of the world</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>11.329992</td>\n",
       "      <td>Psalter</td>\n",
       "      <td>95</td>\n",
       "      <td>O sing unto the Lord a new song; sing unto the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Query  Method  Similarity Score (%)     Text  \\\n",
       "0  for the peace of the world  TF-IDF             18.675396  Psalter   \n",
       "1  for the peace of the world  TF-IDF             18.612013    Bible   \n",
       "2  for the peace of the world  TF-IDF             15.302092  Psalter   \n",
       "3  for the peace of the world  TF-IDF             14.183477    Bible   \n",
       "4  for the peace of the world  TF-IDF             12.570603    Bible   \n",
       "5  for the peace of the world  TF-IDF             11.329992  Psalter   \n",
       "\n",
       "   Psalm Num                                              Verse  \n",
       "0        121  I was glad because of them that said to me, Le...  \n",
       "1        121  1An ode of ascents Iwas glad when they said to...  \n",
       "2         97  O sing unto the Lord a new song, for the Lord ...  \n",
       "3         97  A psalm by David Sing a new song to the Lord F...  \n",
       "4         92  1For the day before the Sabbath when the earth...  \n",
       "5         95  O sing unto the Lord a new song; sing unto the...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b8016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for q in queries:\n",
    "    record_results(q['text'], query_tfidf(q['text']))\n",
    "    \n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcbd3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the rest of the results to the undscored csv file\n",
    "import os\n",
    "\n",
    "output_file = \"results.csv\"\n",
    "\n",
    "full_results.to_csv(\n",
    "    output_file,\n",
    "    mode=\"a\",\n",
    "    index=False,\n",
    "    header=not os.path.exists(output_file)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
